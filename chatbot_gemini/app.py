"""
Chatbot com Gemini AI e Streamlit

Funcionalidades:
- Interface de chat limpa e responsiva
- Configura√ß√£o de API KEY na sidebar
- Hist√≥rico de conversa persistente
- Bot√£o para limpar o hist√≥rico
- Tratamento de erros robusto
- Respostas em tempo real (streaming)
"""

import google.generativeai as gemini
import streamlit as st
from typing import List, Dict

# ============================================
# CONSTANTES E CONFIGURA√á√ïES
# ============================================
DEFAULT_MESSAGE = {
    "role": "assistant", 
    "content": "Ol√°! Eu sou o Gemini. Como posso ajudar voc√™ hoje?"
}
MODEL_NAME = "gemini-1.5-flash"  # Modelo mais recente
SAFETY_SETTINGS = {
    'HARM_CATEGORY_HARASSMENT': 'BLOCK_ONLY_HIGH',
    'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_ONLY_HIGH',
    'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_ONLY_HIGH',
    'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_ONLY_HIGH',
}

# ============================================
# FUN√á√ïES DE INICIALIZA√á√ÉO
# ============================================
def initialize_session_state():
    """Inicializa o hist√≥rico de mensagens se n√£o existir"""
    if "messages" not in st.session_state:
        st.session_state.messages = [DEFAULT_MESSAGE]

def configure_gemini(api_key: str):
    """Configura a API do Gemini"""
    try:
        gemini.configure(api_key=api_key)
    except Exception as e:
        st.error(f"Erro na configura√ß√£o da API: {str(e)}")
        st.stop()

# ============================================
# COMPONENTES DA INTERFACE
# ============================================
def setup_sidebar():
    """Configura a barra lateral com inputs e controles"""
    with st.sidebar:
        st.title("‚öôÔ∏è Configura√ß√µes")
        st.markdown("---")
        
        # Input da API Key
        api_key = st.text_input(
            "üîë Insira sua API Key do Gemini",
            type="password",
            help="Obtenha sua API Key em: https://aistudio.google.com/app/apikey"
        )
        
        if not api_key:
            st.warning("Por favor, insira sua API Key para continuar")
            st.stop()
        
        configure_gemini(api_key)
        
        # Controles adicionais
        st.markdown("---")
        st.markdown("### üõ†Ô∏è Controles")
        
        if st.button("üßπ Limpar Hist√≥rico", help="Reinicia a conversa"):
            st.session_state.messages = [DEFAULT_MESSAGE]
            st.rerun()
        
        return api_key

def display_chat_history():
    """Exibe o hist√≥rico completo da conversa"""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ============================================
# L√ìGICA DO CHATBOT
# ============================================
def generate_gemini_response(prompt: str) -> str:
    """Gera resposta usando a API do Gemini com streaming"""
    try:
        model = gemini.GenerativeModel(MODEL_NAME)
        
        # Prepara o hist√≥rico como contexto
        chat_history = [
            {"role": msg["role"], "parts": [msg["content"]]} 
            for msg in st.session_state.messages
        ]
        
        # Cria o stream de resposta
        response = model.generate_content(
            contents=chat_history + [{"role": "user", "parts": [prompt]}],
            safety_settings=SAFETY_SETTINGS,
            stream=True
        )
        
        return response
        
    except Exception as e:
        raise Exception(f"Erro ao gerar resposta: {str(e)}")

def process_user_input(prompt: str):
    """Processa o input do usu√°rio e gera a resposta"""
    # Adiciona mensagem do usu√°rio ao hist√≥rico
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Exibe mensagem do usu√°rio
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Gera e exibe resposta do assistente
    with st.chat_message("assistant"):
        try:
            message_placeholder = st.empty()
            full_response = ""
            
            with st.spinner("üîç Pensando..."):
                response = generate_gemini_response(prompt)
                
                # Stream da resposta
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "‚ñå")
                
                message_placeholder.markdown(full_response)
            
            # Adiciona resposta ao hist√≥rico
            st.session_state.messages.append(
                {"role": "assistant", "content": full_response}
            )
            
        except Exception as e:
            error_msg = f"‚ö†Ô∏è Ocorreu um erro: {str(e)}"
            st.error(error_msg)
            st.session_state.messages.append(
                {"role": "assistant", "content": error_msg}
            )

# ============================================
# FUN√á√ÉO PRINCIPAL
# ============================================
def main():
    """Fun√ß√£o principal do aplicativo"""
    # Configura√ß√£o da p√°gina
    st.set_page_config(
        page_title="Chatbot Gemini",
        page_icon="ü§ñ",
        layout="centered"
    )
    
    st.title("ü§ñ Chatbot com Gemini AI")
    st.caption("Converse com a IA generativa do Google")
    
    # Configura sidebar e obt√©m API Key
    setup_sidebar()
    
    # Inicializa estado da sess√£o
    initialize_session_state()
    
    # Exibe hist√≥rico do chat
    display_chat_history()
    
    # Input do usu√°rio
    if prompt := st.chat_input("Digite sua mensagem..."):
        process_user_input(prompt)

if __name__ == "__main__":
    main()